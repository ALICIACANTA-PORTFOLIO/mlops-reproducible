# Proyecto MLOps - Clasificaci√≥n de Obesidad

Un proyecto de Machine Learning Operations (MLOps) limpio, ordenado y funcional para la clasificaci√≥n de obesidad. Implementa las mejores pr√°cticas de MLOps con un enfoque profesional y reproducible.

## üåü Caracter√≠sticas Destacadas

‚úÖ **MLflow Model Registry** - Versionado y lifecycle management de modelos  
‚úÖ **Model Signatures** - Validaci√≥n autom√°tica de schemas input/output  
‚úÖ **DVC Integration** - Versionado de datos y reproducibilidad  
‚úÖ **FastAPI** - API REST production-ready  
‚úÖ **Pytest** - Suite completa de pruebas  
‚úÖ **Enterprise-Grade** - Automatizaci√≥n de transiciones de modelos (Staging ‚Üí Production)

---

## üè∑Ô∏è Model Registry

El proyecto implementa **MLflow Model Registry** con capacidades avanzadas:

```bash
# Listar modelos registrados
python manage_registry.py list

# Ver versiones y m√©tricas
python manage_registry.py versions obesity_classifier

# Promover modelo a Production
python manage_registry.py promote obesity_classifier 2 Production

# Asignar alias "champion"
python manage_registry.py alias obesity_classifier champion 2

# Comparar versiones
python manage_registry.py compare obesity_classifier 1 2

# Encontrar mejor modelo
python manage_registry.py best obesity_classifier --metric accuracy
```

**Caracter√≠sticas**:
- üîÑ Registro autom√°tico durante entrenamiento
- ‚úÖ Model signatures para validaci√≥n
- üìä Transiciones autom√°ticas a Staging (accuracy >= 0.85)
- üèÜ Sistema de aliases (champion, challenger)
- üìà Tags enriquecidos con metadata
- üîç CLI completa para gesti√≥n

**Documentaci√≥n completa**: [docs/MODEL_REGISTRY.md](docs/MODEL_REGISTRY.md)

---

## üß™ Pruebas

```bash
# Ejecutar todas las pruebas
python -m pytest tests/ -v

# Pruebas espec√≠ficas
python -m pytest tests/test_data_validation.py -v

# Probar API (si est√° corriendo)
python test_api.py
```

## üìù Requisitos

- Python 3.8+
- scikit-learn 1.3+
- pandas 2.0+
- numpy 1.21+
- mlflow 2.0+ (opcional)
- dvc 3.0+ (opcional)

## ü§ù Contribuci√≥n

Este es un proyecto de portfolio que demuestra implementaci√≥n profesional de MLOps siguiendo las mejores pr√°cticas de la industria.

## üìÑ Licencia

Proyecto educativo - MIT License

---

## ÔøΩ Estructura del Proyecto (Arquitectura H√≠brida)

```
mlops-reproducible/
‚îú‚îÄ‚îÄ src/                      # üîß M√≥dulos CLI (DVC Pipeline)
‚îÇ   ‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ preprocess.py     # Limpieza y validaci√≥n de datos
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ make_features.py  # Ingenier√≠a de caracter√≠sticas
‚îÇ   ‚îî‚îÄ‚îÄ models/
‚îÇ       ‚îú‚îÄ‚îÄ train.py          # Entrenamiento con MLflow
‚îÇ       ‚îú‚îÄ‚îÄ evaluate.py       # Evaluaci√≥n y m√©tricas
‚îÇ       ‚îî‚îÄ‚îÄ predict.py        # Predicciones batch
‚îú‚îÄ‚îÄ mlops/                    # üêç API Python (Uso Interactivo)
‚îÇ   ‚îú‚îÄ‚îÄ __init__.py          # Inicializaci√≥n del m√≥dulo
‚îÇ   ‚îú‚îÄ‚îÄ config.py            # Gesti√≥n de configuraci√≥n
‚îÇ   ‚îú‚îÄ‚îÄ dataset.py           # Procesamiento de datos
‚îÇ   ‚îú‚îÄ‚îÄ features.py          # Ingenier√≠a de caracter√≠sticas
‚îÇ   ‚îú‚îÄ‚îÄ modeling.py          # Entrenamiento y evaluaci√≥n
‚îÇ   ‚îî‚îÄ‚îÄ train.py            # Pipeline principal
‚îú‚îÄ‚îÄ data/                    # üìä Datos versionados con DVC
‚îÇ   ‚îú‚îÄ‚îÄ raw/                # Datos originales
‚îÇ   ‚îú‚îÄ‚îÄ interim/            # Datos procesados intermedio
‚îÇ   ‚îî‚îÄ‚îÄ processed/          # Datos finales procesados
‚îú‚îÄ‚îÄ models/                  # ü§ñ Modelos entrenados
‚îú‚îÄ‚îÄ notebooks/               # üìì Notebooks de exploraci√≥n
‚îú‚îÄ‚îÄ reports/                 # üìà Reportes y m√©tricas
‚îú‚îÄ‚îÄ docs/                    # üìö Documentaci√≥n
‚îú‚îÄ‚îÄ tests/                   # üß™ Pruebas unitarias
‚îú‚îÄ‚îÄ run_mlops.py            # üöÄ Interface unificada
‚îú‚îÄ‚îÄ params.yaml              # ‚öôÔ∏è Configuraci√≥n principal
‚îú‚îÄ‚îÄ dvc.yaml                 # üîÑ Pipeline DVC
‚îî‚îÄ‚îÄ requirements.txt         # üì¶ Dependencias
```

## üéØ Dos Enfoques, Una Funcionalidad

### **Enfoque 1: `src/` - M√≥dulos CLI (Recomendado para Producci√≥n)**

- ‚úÖ **DVC Integration** - Perfecto para pipelines automatizados
- ‚úÖ **Modular** - Cada script es independiente
- ‚úÖ **CI/CD Ready** - F√°cil integraci√≥n en workflows
- ‚úÖ **MLflow Tracking** - Registro autom√°tico de experimentos

### **Enfoque 2: `mlops/` - Python API (Recomendado para Desarrollo)**

- ‚úÖ **Interactive** - Perfecto para notebooks y experimentaci√≥n
- ‚úÖ **Clean API** - Interfaz Python elegante y f√°cil de usar
- ‚úÖ **Integrated** - Pipeline completo en una sola llamada
- ‚úÖ **Flexible** - Configuraci√≥n program√°tica

---

## üß© Flujo MLOps Implementado

```mermaid
flowchart LR
    A[üìä Datos brutos] --> B[üßπ Limpieza DVC]
    B --> C[‚öôÔ∏è Feature Engineering]
    C --> D[ü§ñ Entrenamiento MLflow]
    D --> E[üìà Model Registry]
    E --> F[üöÄ Production]
    F --> G[üì° Monitoring]
```

**Pipeline Completo**:
1. **DVC** versiona datos y reproduce pipeline
2. **MLflow** trackea experimentos y registra modelos
3. **Model Registry** gestiona lifecycle (Staging ‚Üí Production)
4. **FastAPI** sirve predicciones
5. **Pytest** valida calidad

---

## üìä MLflow: Experiment Tracking & Model Registry

### **¬øQu√© hace MLflow en este proyecto?**

MLflow maneja **todo el ciclo de vida del modelo ML**:

#### **1. Experiment Tracking** 
Cada entrenamiento registra autom√°ticamente:
- ‚úÖ **Par√°metros** (n_estimators, max_depth, etc.)
- ‚úÖ **M√©tricas** (accuracy, F1, precision por clase)
- ‚úÖ **Artefactos** (modelo, confusion matrix, feature importance)
- ‚úÖ **Metadata** (fecha, duraci√≥n, versi√≥n de c√≥digo)

```bash
# Entrenar y trackear autom√°ticamente
python src/models/train.py

# Ver experimentos en UI
mlflow ui
# Abre: http://localhost:5000
```

**Resultado**: Historial completo de experimentos para comparar y reproducir.

#### **2. Model Registry** ‚≠ê (Enterprise-Grade)
Sistema completo de versionado y lifecycle:

```bash
# Ver modelos registrados
python manage_registry.py list

# Ver versiones y m√©tricas
python manage_registry.py versions obesity_classifier
# Output:
# Version | Stage      | Accuracy | F1     | Aliases
# 2       | Production | 0.9266   | 0.9251 | champion
# 1       | None       | 0.9266   | 0.9251 | -

# Promover a Production
python manage_registry.py promote obesity_classifier 2 Production

# Asignar alias para uso f√°cil
python manage_registry.py alias obesity_classifier champion 2
```

**Uso en c√≥digo**:
```python
import mlflow

# Cargar modelo por alias (recomendado)
model = mlflow.pyfunc.load_model("models:/obesity_classifier@champion")
predictions = model.predict(new_data)
```

**Caracter√≠sticas avanzadas**:
- üîÑ **Transiciones autom√°ticas**: Si accuracy >= 0.85 ‚Üí auto-promoci√≥n a Staging
- ‚úÖ **Model Signatures**: Validaci√≥n autom√°tica de schemas input/output
- üìä **Metadata enriquecido**: Tags (model_type, training_date, validation_status)
- üèÜ **Aliases sem√°nticos**: champion, challenger, baseline

**Documentaci√≥n completa**: [docs/MODEL_REGISTRY.md](docs/MODEL_REGISTRY.md)

---

## üîÑ DVC: Data Version Control & Pipeline

### **¬øQu√© hace DVC en este proyecto?**

DVC maneja **versionado de datos y reproducibilidad del pipeline**:

#### **1. Versionado de Datos**
Los datos grandes se versioanan con DVC (no con Git):

```bash
# Ver datos versionados
cat data/raw/ObesityDataSet_raw_and_data_sinthetic.csv.dvc

# Descargar datos (si no los tienes)
dvc pull

# Actualizar datos
dvc add data/raw/nuevo_dataset.csv
git add data/raw/nuevo_dataset.csv.dvc
git commit -m "Update dataset"
dvc push
```

**Beneficio**: Git solo guarda el hash, no archivos grandes (2.1MB versionado como 165 bytes).

#### **2. Pipeline Reproducible**
`dvc.yaml` define el pipeline completo con dependencias:

```yaml
stages:
  preprocess:
    cmd: python src/data/preprocess.py
    deps:
      - data/raw/ObesityDataSet_raw_and_data_sinthetic.csv
    outs:
      - data/interim/obesity_clean.csv
      
  make_features:
    cmd: python src/data/make_features.py
    deps:
      - data/interim/obesity_clean.csv
    outs:
      - data/processed/features.csv
      
  train:
    cmd: python src/models/train.py
    deps:
      - data/processed/features.csv
      - params.yaml
    outs:
      - models/obesity_model.pkl
      - reports/metrics.json
```

**Ejecutar pipeline completo**:
```bash
# Reproducir todo el pipeline
dvc repro

# Ver DAG visual
dvc dag

# Output:
# +--------------+
# | preprocess   |
# +--------------+
#       *
#       *
#       *
# +--------------+
# | make_features|
# +--------------+
#       *
#       *
#       *
# +--------------+
# | train        |
# +--------------+
```

**DVC solo re-ejecuta stages modificados** (cache inteligente).

#### **3. Reproducibilidad Garantizada**
```bash
# Alguien clona tu repo
git clone <repo>
dvc pull  # Descarga datos

# Reproduce exactamente tus resultados
dvc repro

# Resultado: Mismo modelo, mismas m√©tricas (0.0000 difference)
```

**Validado con tests**:
```bash
pytest tests/test_data_validation.py::test_reproducibility
# ‚úÖ PASSED - Difference: 0.0000000000
```

---

## üîó MLflow + DVC: Mejor Juntos

| Herramienta | Qu√© versiona | Cu√°ndo usar |
|-------------|--------------|-------------|
| **Git** | C√≥digo Python, configs | Siempre |
| **DVC** | Datos, modelos grandes | Archivos > 1MB |
| **MLflow** | Experimentos, par√°metros, m√©tricas | Cada entrenamiento |

**Workflow combinado**:
```bash
# 1. DVC reproduce pipeline
dvc repro

# 2. MLflow trackea experimentos autom√°ticamente
# (cada stage de DVC registra en MLflow)

# 3. Git versiona c√≥digo + metadatos
git add dvc.lock params.yaml
git commit -m "Experiment: increased max_depth"

# 4. DVC versiona datos y modelos
dvc push

# 5. MLflow Model Registry gestiona lifecycle
python manage_registry.py promote obesity_classifier 2 Production
```

**Resultado**: Reproducibilidad total con historial completo.

---

## ‚öôÔ∏è Stack Tecnol√≥gico

| Categor√≠a | Herramienta | Prop√≥sito | Uso en el proyecto |
|-----------|-------------|-----------|-------------------|
| üêç **Core** | Python 3.10 | Lenguaje base | Todo el c√≥digo |
| üìä **ML** | scikit-learn | Modelo ML | RandomForest (92.66% accuracy) |
| üîÑ **Data Versioning** | **DVC 3.30** | Versionar datos/modelos | `dvc.yaml` pipeline + `dvc pull/push` |
| üìà **Experiment Tracking** | **MLflow 2.8** | Trackear experimentos | Auto-logging en `train.py` |
| üè∑Ô∏è **Model Registry** | **MLflow Registry** | Lifecycle de modelos | Staging ‚Üí Production |
| ‚ö° **API** | FastAPI | Servir predicciones | REST API en `start_api.py` |
| üß™ **Testing** | Pytest | Testing automatizado | 3/3 tests passing |
| üì¶ **Environment** | Conda | Gesti√≥n de entorno | Python 3.10.19 reproducible |
| üìù **Config** | YAML | Configuraci√≥n | `params.yaml`, `dvc.yaml` |
| üîç **Version Control** | Git/GitHub | C√≥digo versionado | Repo completo |

### **Comandos R√°pidos por Herramienta**:

#### **DVC** (Datos y Pipeline)
```bash
dvc pull              # Descargar datos
dvc repro             # Ejecutar pipeline completo
dvc dag               # Ver grafo de dependencias
dvc push              # Subir datos/modelos
```

#### **MLflow** (Experimentos y Modelos)
```bash
mlflow ui                                    # Ver experimentos (localhost:5000)
python manage_registry.py list               # Ver modelos registrados
python manage_registry.py versions <model>   # Ver versiones y m√©tricas
```

#### **FastAPI** (Servir Modelo)
```bash
uvicorn start_api:app --reload              # Iniciar API (localhost:8000)
python test_api.py                          # Test API
```

#### **Pytest** (Testing)
```bash
pytest tests/ -v                            # Ejecutar todos los tests
pytest tests/test_data_validation.py -v     # Test espec√≠fico
```

---

## ‚öôÔ∏è Instalaci√≥n y Configuraci√≥n

### **Setup Inicial**

```bash
# 1Ô∏è‚É£ Clonar repositorio
git clone https://github.com/ALICIACANTA-PORTFOLIO/mlops-reproducible.git
cd mlops-reproducible

# 2Ô∏è‚É£ Crear entorno Python 3.10
conda create -n mlops-reproducible python=3.10.19 -y
conda activate mlops-reproducible

# 3Ô∏è‚É£ Instalar dependencias
pip install -r requirements.txt

# 4Ô∏è‚É£ Descargar datos (si est√°n en DVC remote)
dvc pull
```

**Verificaci√≥n**:
```bash
# Ejecutar tests
pytest tests/ -v
# ‚úÖ 3/3 tests passing

# Ver estructura MLflow
ls mlruns/
```

---

## üöÄ Quick Start

### **Opci√≥n 1: Pipeline Completo con DVC** (Recomendado)

```bash
# Ejecutar todas las etapas: preprocess ‚Üí features ‚Üí train
dvc repro

# Ver m√©tricas
dvc metrics show

# Ver DAG del pipeline
dvc dag
```

**Output esperado**:
```
Running stage 'preprocess'...
Running stage 'make_features'...
Running stage 'train'...
‚úÖ Model trained: Accuracy 0.9266

reports/metrics.json:
    accuracy: 0.9266
    f1_macro: 0.9251
```

### **Opci√≥n 2: Entrenar Directamente con MLflow**

```bash
# Entrenar y registrar en MLflow Registry autom√°ticamente
python src/models/train.py \
    --data data/processed/features.csv \
    --params params.yaml \
    --model_dir models \
    --metrics reports/metrics.json

# Ver experimento en UI
mlflow ui
# Abre: http://localhost:5000
```

**Auto-ejecuta**:
- ‚úÖ Tracking de par√°metros (25+ params)
- ‚úÖ Registro de m√©tricas (accuracy, F1, etc.)
- ‚úÖ Registro en Model Registry
- ‚úÖ Transici√≥n a Staging si accuracy >= 0.85

### **Opci√≥n 3: Usar Python API (Desarrollo Interactivo)**

```python
from mlops import train, config

# Cargar configuraci√≥n
params = config.load_params('params.yaml')

# Entrenar modelo
train.train_model(params)
```

---

## üßÆ Trabajar con DVC

### **Ver y modificar par√°metros**

```bash
# Editar configuraci√≥n
nano params.yaml

# Cambiar hiperpar√°metros (ejemplo)
random_forest:
  n_estimators: 200  # era 100
  max_depth: 15      # era 10

# Re-ejecutar pipeline (solo lo modificado)
dvc repro

# Comparar m√©tricas con versi√≥n anterior
dvc metrics diff
```

**Output**:
```diff
Path              Metric     Old      New      Change
reports/metrics.json
                  accuracy   0.9266   0.9312   +0.0046
                  f1_macro   0.9251   0.9298   +0.0047
```

### **Versionado de datos**

```bash
# Agregar nuevo dataset
dvc add data/raw/nuevo_dataset.csv

# Commitear metadata (no el archivo grande)
git add data/raw/nuevo_dataset.csv.dvc .gitignore
git commit -m "Add new dataset"

# Subir datos a remote (si est√° configurado)
dvc push
```

---

## üß† Trabajar con MLflow

### **Ver experimentos en UI**

```bash
# Iniciar interfaz web
mlflow ui

# Abre: http://localhost:5000
```

**En la UI puedes**:
- üìä Comparar experimentos lado a lado
- üìà Ver gr√°ficos de m√©tricas
- üîç Inspeccionar par√°metros y artefactos
- üì• Descargar modelos entrenados

### **Gestionar Model Registry**

```bash
# Listar modelos registrados
python manage_registry.py list

# Ver versiones del modelo
python manage_registry.py versions obesity_classifier

# Comparar dos versiones
python manage_registry.py compare obesity_classifier 1 2

# Promover a Production
python manage_registry.py promote obesity_classifier 2 Production

# Asignar alias "champion"
python manage_registry.py alias obesity_classifier champion 2

# Encontrar mejor modelo
python manage_registry.py best obesity_classifier --metric accuracy
```

### **Usar modelo en c√≥digo**

```python
import mlflow
import pandas as pd

# Cargar modelo por alias (recomendado)
model = mlflow.pyfunc.load_model("models:/obesity_classifier@champion")

# O por stage
model = mlflow.pyfunc.load_model("models:/obesity_classifier/Production")

# O por versi√≥n espec√≠fica
model = mlflow.pyfunc.load_model("models:/obesity_classifier/2")

# Hacer predicci√≥n
new_data = pd.DataFrame([{
    'Age': 25, 'Weight': 80, 'Height': 1.70,
    'FCVC': 2, 'CH2O': 2, 'FAF': 3, ...
}])
prediction = model.predict(new_data)
print(prediction)  # ['Normal_Weight']
```

**Documentaci√≥n completa**: [docs/MODEL_REGISTRY.md](docs/MODEL_REGISTRY.md)

---

## üåê API REST con FastAPI

### **Iniciar servidor**

```bash
# Desarrollo (auto-reload)
uvicorn start_api:app --reload --port 8000

# Producci√≥n
uvicorn start_api:app --host 0.0.0.0 --port 8000
```

**Endpoints disponibles**: http://localhost:8000/docs (Swagger UI autom√°tica)

### **Realizar predicciones**

```bash
# Predicci√≥n individual
curl -X POST "http://localhost:8000/predict" \
  -H "Content-Type: application/json" \
  -d '{
    "Age": 25,
    "Height": 1.70,
    "Weight": 80,
    "FCVC": 2,
    "CH2O": 2,
    "FAF": 3,
    "TUE": 1,
    "CALC": 2,
    "MTRANS": "Public_Transportation"
  }'

# Response:
# {
#   "prediction": "Normal_Weight",
#   "probabilities": {
#     "Normal_Weight": 0.89,
#     "Overweight_Level_I": 0.08,
#     "Obesity_Type_I": 0.03
#   }
# }
```

### **Test automatizado de API**

```bash
# Ejecutar todos los tests de API
python test_api.py

# Output:
# ‚úÖ Health check passed
# ‚úÖ Single prediction passed
# ‚úÖ Batch prediction passed
# ‚úÖ Model info passed
# 4/4 tests successful
```

üß™ Pruebas autom√°ticas

:: Ejecutar tests unitarios y de integraci√≥n:
```bash
    pytest -q

üîÅ Integraci√≥n continua (CI)
Cada push al repositorio activa el flujo de CI definido en .github/workflows/ci.yml, que ejecuta:
```bash
    dvc repro
    pytest
    dvc metrics show

Esto asegura reproducibilidad y validaci√≥n autom√°tica de los cambios.

üßë‚Äçüíª Roles simulados en el flujo MLOps
Rol         	    Responsabilidad
Data Engineer	    Limpieza, integraci√≥n y versionado de datos.
Data Scientist	    Exploraci√≥n, modelado y m√©tricas.
ML Engineer	        Empaquetado, entrenamiento y evaluaci√≥n automatizada.
DevOps Engineer	    Automatizaci√≥n, CI/CD y monitoreo de despliegues.

üìà M√©tricas base (ejemplo)
M√©trica	        Valor
Accuracy	    0.972
F1-macro	    0.961
Recall	        0.958
Precision	    0.965

Los resultados pueden variar seg√∫n los hiperpar√°metros definidos en params.yaml.

üß≠ Lecciones aprendidas
- La reproducibilidad es la clave del √©xito en Machine Learning.
- Versionar datos y modelos permite auditar y mejorar continuamente.
- MLflow y DVC simplifican el control de experimentos.
- La colaboraci√≥n entre roles t√©cnicos asegura trazabilidad y calidad.
- CI/CD garantiza estabilidad en cada versi√≥n del pipeline.

üß© Pr√≥ximos pasos
- Incorporar monitoreo con EvidentlyAI.
- Automatizar el reentrenamiento por data drift.
- Contenerizar todo el flujo con Docker Compose.
- Desplegar en nube (AWS / Azure / GCP).

üìö Referencias
- Introducing MLOps ‚Äì Mark Treveil, O‚ÄôReilly Media (2020).
- Machine Learning Engineering in Action ‚Äì Ben Wilson (2022).
- Documentaci√≥n oficial: DVC
 | MLflow

üèÅ Conclusi√≥n

‚ÄúLa reproducibilidad es el puente entre la experimentaci√≥n y la producci√≥n.‚Äù
Este proyecto demuestra c√≥mo implementar un flujo MLOps real: automatizado, trazable y escalable.

---

üìò **Instrucciones finales:**
1. Copia todo el bloque de arriba.
2. Crea un nuevo archivo llamado `README.md` en tu repositorio local (`mlops-reproducible/`).
3. Pega el contenido y guarda.
4. Ejecuta:
   ```bash
   git add README.md
   git commit -m "Add professional README for MLOps reproducible project"
   git push origin main
````
