# Proyecto MLOps - ClasificaciÃ³n de Obesidad

Un proyecto de Machine Learning Operations (MLOps) limpio, ordenado y funcional para la clasificaciÃ³n de obesidad. Implementa las mejores prÃ¡cticas de MLOps con un enfoque profesional y reproducible.

## ğŸ¯ Objetivo

Crear un pipeline de machine learning reproducible y profesional para clasificar niveles de obesidad utilizando datos demogrÃ¡ficos y hÃ¡bitos alimentarios.

## ï¿½ Estructura del Proyecto

```
mlops-reproducible/
â”œâ”€â”€ mlops/                     # Paquete principal MLOps
â”‚   â”œâ”€â”€ __init__.py           # InicializaciÃ³n del mÃ³dulo
â”‚   â”œâ”€â”€ config.py             # GestiÃ³n de configuraciÃ³n
â”‚   â”œâ”€â”€ dataset.py            # Procesamiento de datos
â”‚   â”œâ”€â”€ features.py           # IngenierÃ­a de caracterÃ­sticas
â”‚   â”œâ”€â”€ modeling.py           # Entrenamiento y evaluaciÃ³n
â”‚   â””â”€â”€ train.py             # Pipeline principal
â”œâ”€â”€ data/                     # Datos versionados con DVC
â”‚   â”œâ”€â”€ raw/                 # Datos originales
â”‚   â”œâ”€â”€ interim/             # Datos procesados intermedio
â”‚   â””â”€â”€ processed/           # Datos finales procesados
â”œâ”€â”€ models/                  # Modelos entrenados
â”œâ”€â”€ notebooks/               # Notebooks de exploraciÃ³n
â”œâ”€â”€ reports/                 # Reportes y mÃ©tricas
â”œâ”€â”€ docs/                    # DocumentaciÃ³n
â”œâ”€â”€ tests/                   # Pruebas unitarias
â”œâ”€â”€ params.yaml              # ConfiguraciÃ³n principal
â”œâ”€â”€ dvc.yaml                 # Pipeline DVC
â””â”€â”€ requirements.txt         # Dependencias
```

## ğŸš€ InstalaciÃ³n RÃ¡pida

```bash
# Clonar el repositorio
git clone <repository-url>
cd mlops-reproducible

# Instalar dependencias
pip install -r requirements.txt

# Configurar DVC (opcional)
dvc pull
```

## ğŸ“Š Datos

**Dataset**: ClasificaciÃ³n de Obesidad

- **Muestras**: 2,089 registros
- **CaracterÃ­sticas**: 16 variables (edad, peso, altura, hÃ¡bitos)
- **Clases**: 7 niveles de obesidad
- **Fuente**: Datos sintÃ©ticos y reales de hÃ¡bitos alimentarios

### Variables Principales:

- DemogrÃ¡ficas: Edad, GÃ©nero, Peso, Altura
- HÃ¡bitos: Frecuencia comidas, Consumo vegetales, Actividad fÃ­sica
- Comportamiento: Uso tecnologÃ­a, Consumo alcohol, Transporte

## ï¿½ Uso del Sistema - Interface Unificada

### **OpciÃ³n A: Interface Unificada (Recomendada)**

```bash
# Pipeline completo - Enfoque CLI (DVC/ProducciÃ³n)
python run_mlops.py cli pipeline --params params.yaml

# Pipeline completo - Enfoque API (Desarrollo/Interactivo)
python run_mlops.py api pipeline --params params.yaml --experiment obesity_v1

# Pasos individuales - CLI
python run_mlops.py cli preprocess --input data/raw/dataset.csv --output data/interim/clean.csv
python run_mlops.py cli features --input data/interim/clean.csv --output data/processed/features.csv
python run_mlops.py cli train --data data/processed/features.csv
python run_mlops.py cli evaluate --data data/processed/features.csv
python run_mlops.py cli predict --model models/mlflow_model --features data/processed/features.csv

# Pasos individuales - API
python run_mlops.py api train --params params.yaml --experiment obesity_v1
python run_mlops.py api predict --model models/model.pkl --data data/new.csv --output predictions.csv
```

### **OpciÃ³n B: Uso Directo - Enfoque CLI (`src/`)**

```bash
# Pipeline paso a paso
python src/data/preprocess.py --inp data/raw/dataset.csv --out data/interim/clean.csv
python src/data/make_features.py --inp data/interim/clean.csv --out data/processed/features.csv
python src/models/train.py --data data/processed/features.csv
python src/models/evaluate.py --data data/processed/features.csv
python src/models/predict.py --features_csv data/processed/features.csv

# O usando DVC (recomendado para producciÃ³n)
dvc repro  # Ejecuta todo el pipeline definido en dvc.yaml
```

### **OpciÃ³n C: Uso Directo - Enfoque API (`mlops/`)**

```python
# Entrenamiento bÃ¡sico
from mlops import train_model
results = train_model()
print(f"Accuracy: {results['test_metrics']['accuracy']:.3f}")

# Uso paso a paso
from mlops import Config, DataProcessor, FeatureEngineer, ModelTrainer

config = Config("params.yaml")
processor = DataProcessor(config.config)
engineer = FeatureEngineer(config.config)
trainer = ModelTrainer(config.config)

# Procesamiento completo
df = processor.load_data("data/raw/dataset.csv")
X_train, X_test, y_train, y_test = processor.split_data(df)
X_train_feat = engineer.create_features(X_train)
model = trainer.train_model(X_train_feat, y_train)

# Predicciones
from mlops import predict_batch
predictions = predict_batch(
    model_path="models/model.pkl",
    data_path="data/new_data.csv",
    output_path="predictions.csv"
)
```

## âš™ï¸ ConfiguraciÃ³n

El archivo `params.yaml` controla todos los aspectos del pipeline:

```yaml
# Datos
data:
  raw_path: "data/raw/ObesityDataSet_raw_and_data_sinthetic.csv"
  target_column: "NObeyesdad"
  test_size: 0.2

# CaracterÃ­sticas
features:
  selection_method: "mutual_info"
  n_features: 10
  create_interactions: true

# Modelo
model:
  hyperparameter_tuning: true
  cv_folds: 5
  parameters:
    n_estimators: 200
    max_depth: 15
    random_state: 42

# MLflow
mlflow:
  tracking: true
  experiment_name: "obesity_classification"
```

## ğŸ”„ Pipeline MLOps Completo

### **Arquitectura de Doble Enfoque**

| Fase                       | `src/` CLI Modules          | `mlops/` Python API      | PropÃ³sito                         |
| -------------------------- | --------------------------- | ------------------------ | --------------------------------- |
| **1. Preprocessing**       | `src/data/preprocess.py`    | `mlops.DataProcessor`    | Limpieza, validaciÃ³n, imputaciÃ³n  |
| **2. Feature Engineering** | `src/data/make_features.py` | `mlops.FeatureEngineer`  | CodificaciÃ³n, escalado, selecciÃ³n |
| **3. Training**            | `src/models/train.py`       | `mlops.ModelTrainer`     | Entrenamiento con MLflow tracking |
| **4. Evaluation**          | `src/models/evaluate.py`    | `mlops.evaluate_model()` | MÃ©tricas y visualizaciones        |
| **5. Prediction**          | `src/models/predict.py`     | `mlops.predict_batch()`  | Inferencia batch/online           |

### **Funcionalidades Clave**

#### **Procesamiento (`src/data/`)**

- âœ… **Limpieza inteligente** - EliminaciÃ³n duplicados, validaciÃ³n rangos
- âœ… **ImputaciÃ³n configurable** - Estrategias por tipo de variable
- âœ… **NormalizaciÃ³n strings** - Consistencia en categÃ³ricas
- âœ… **Reporte de calidad** - JSON con mÃ©tricas de limpieza

#### **Features (`src/data/make_features.py`)**

- âœ… **Encoding flexible** - OneHot, Ordinal, Label encoding
- âœ… **Scaling robusto** - Standard, MinMax, Robust scalers
- âœ… **Artefactos ML** - Guardado automÃ¡tico encoder/scaler
- âœ… **Target mapping** - CodificaciÃ³n consistente del target

#### **Entrenamiento (`src/models/`)**

- âœ… **MLflow integration** - Tracking automÃ¡tico experimentos
- âœ… **MÃºltiples algoritmos** - RandomForest, LogisticRegression
- âœ… **MÃ©tricas completas** - Accuracy, F1-macro, Precision, Recall
- âœ… **Visualizaciones** - Matriz confusiÃ³n, feature importance

#### **API Python (`mlops/`)**

- âœ… **Interface limpia** - Uso programÃ¡tico sencillo
- âœ… **Pipeline integrado** - Una llamada, pipeline completo
- âœ… **ConfiguraciÃ³n flexible** - YAML + overrides programÃ¡ticos
- âœ… **Interoperabilidad** - Compatible con notebooks

## ğŸ“ˆ MÃ©tricas de Rendimiento

### **Resultados TÃ­picos (Dataset Obesidad)**

- **Accuracy**: 91.5% - 96.5%
- **F1-macro**: 91.2% - 96.2%
- **F1-weighted**: ~96.5%
- **Cross-validation**: 95.8% Â± 1.2%

## ğŸ› ï¸ CaracterÃ­sticas TÃ©cnicas

### **Arquitectura HÃ­brida Ãšnica**

- âœ… **Doble enfoque** - CLI para producciÃ³n, API para desarrollo
- âœ… **Interoperabilidad** - Ambas estructuras usan la misma configuraciÃ³n
- âœ… **Flexibilidad** - Elige el enfoque segÃºn tu caso de uso
- âœ… **Consistencia** - Resultados idÃ©nticos en ambos enfoques

### **Calidad de CÃ³digo**

- âœ… **Type hints completos** - Tanto en `src/` como `mlops/`
- âœ… **DocumentaciÃ³n exhaustiva** - Docstrings y comentarios detallados
- âœ… **Validaciones robustas** - Control de errores en ambos enfoques
- âœ… **Patrones profesionales** - Siguiendo mejores prÃ¡cticas de MLOps

### **MLOps Completo**

- âœ… **Versionado de datos** - DVC integration nativa
- âœ… **Experiment tracking** - MLflow automÃ¡tico en ambos enfoques
- âœ… **Reproducibilidad** - ConfiguraciÃ³n centralizada `params.yaml`
- âœ… **Artefactos ML** - Guardado automÃ¡tico de encoders/scalers/modelos

## ğŸ¯ CuÃ¡ndo Usar Cada Enfoque

### **Usa `src/` CLI cuando:**

- ğŸ—ï¸ **Configurando pipelines DVC** para producciÃ³n
- ğŸ¤– **Implementando CI/CD** automatizado
- ğŸ”„ **Necesites ejecuciÃ³n modular** paso a paso
- ğŸ“Š **Trabajando con grandes volÃºmenes** de datos

### **Usa `mlops/` API cuando:**

- ğŸ““ **Desarrollando en Jupyter** notebooks
- ğŸ”¬ **Experimentando interactivamente** con parÃ¡metros
- ğŸš€ **Prototipando rÃ¡pidamente** nuevas ideas
- ğŸ **Integrando en aplicaciones** Python existentes

### **Usa Interface Unificada (`run_mlops.py`) cuando:**

- ğŸŒŸ **Quieras lo mejor de ambos** mundos
- ğŸ”§ **EstÃ©s aprendiendo MLOps** y quieras flexibilidad
- ğŸ›ï¸ **Necesites cambiar entre enfoques** dinÃ¡micamente
- ğŸ“š **EstÃ©s documentando** o enseÃ±ando MLOps

## ğŸ“š DocumentaciÃ³n Adicional

- [`docs/GRADIO_INTERFACE.md`](docs/GRADIO_INTERFACE.md) - **ğŸ¨ Interfaz web amigable (Gradio UI)**
- [`docs/API_DOCUMENTATION.md`](docs/API_DOCUMENTATION.md) - **ğŸš€ API REST para servir el modelo (FastAPI)**
- [`docs/MLOPS_INTEGRATION.md`](docs/MLOPS_INTEGRATION.md) - **GuÃ­a completa de integraciÃ³n MLOps (DVC + MLflow + CI/CD)**
- [`docs/TECHNICAL_GUIDE.md`](docs/TECHNICAL_GUIDE.md) - GuÃ­a tÃ©cnica detallada
- [`docs/ARCHITECTURE.md`](docs/ARCHITECTURE.md) - Arquitectura del sistema
- [`docs/DEPLOYMENT.md`](docs/DEPLOYMENT.md) - GuÃ­a de despliegue
- [`notebooks/EDA.ipynb`](notebooks/EDA.ipynb) - AnÃ¡lisis exploratorio

## ğŸš€ **API REST - Servir el Modelo**

### **Inicio RÃ¡pido de la API:**

```bash
# 1. Entrenar el modelo (si no estÃ¡ entrenado)
python run_mlops.py cli pipeline

# 2. Iniciar la API
python start_api.py --reload

# 3. Probar la API
python test_api.py
```

### **Endpoints Principales:**

- **GET** `/health` - Health check de la API
- **POST** `/predict` - PredicciÃ³n individual
- **POST** `/predict/batch` - Predicciones en lote
- **GET** `/model/info` - InformaciÃ³n del modelo
- **GET** `/docs` - DocumentaciÃ³n interactiva (Swagger)

### **Ejemplo de Uso:**

```python
import requests

# Datos de ejemplo
data = {
    "Age": 28, "Height": 1.75, "Weight": 85,
    "Gender": "Male", "FAVC": "yes",
    # ... resto de campos
}

# PredicciÃ³n
response = requests.post("http://127.0.0.1:8000/predict", json=data)
result = response.json()

print(f"PredicciÃ³n: {result['prediction']}")
print(f"Confianza: {result['confidence']:.3f}")
print(f"Nivel de riesgo: {result['risk_level']}")
```

**ğŸ“‹ DocumentaciÃ³n completa**: [`docs/API_DOCUMENTATION.md`](docs/API_DOCUMENTATION.md)

## ğŸ¨ **Interfaz Web Gradio - UI Amigable**

### **Interfaz Visual para Usuarios Finales:**

```bash
# 1. Instalar dependencias (si no estÃ¡n)
pip install gradio plotly

# 2. Entrenar el modelo (si no estÃ¡ entrenado)
python run_mlops.py cli pipeline

# 3. Iniciar interfaz Gradio
python start_gradio.py

# 4. Abrir en navegador
# http://127.0.0.1:7860
```

### **ğŸŒŸ CaracterÃ­sticas de la Interfaz:**

- **ğŸ¯ Formulario interactivo** - Sliders, dropdowns, radio buttons
- **ğŸ“Š Visualizaciones en tiempo real** - GrÃ¡ficos Plotly interactivos
- **ğŸ’¡ Recomendaciones personalizadas** - Consejos especÃ­ficos por resultado
- **ğŸ”¬ Casos de ejemplo** - Datos predefinidos para prueba rÃ¡pida
- **ğŸ“± DiseÃ±o responsivo** - Se adapta a mÃ³viles y tablets
- **ğŸ¨ Interfaz profesional** - Tema personalizado y atractivo

### **ğŸ® Ejemplo de Uso Gradio:**

1. **ğŸ“ Llenar formulario** - Edad, peso, altura, hÃ¡bitos
2. **ğŸ¯ Hacer clic** en "Analizar mi Estado de Salud"
3. **ğŸ“Š Ver resultados** - ClasificaciÃ³n + confianza + grÃ¡ficos
4. **ğŸ’¡ Leer consejos** - Recomendaciones personalizadas

### **ğŸ¯ ComparaciÃ³n: FastAPI vs Gradio**

| Interfaz    | Audiencia        | Formato   | Uso Principal        |
| ----------- | ---------------- | --------- | -------------------- |
| **FastAPI** | Desarrolladores  | JSON/REST | IntegraciÃ³n con apps |
| **Gradio**  | Usuarios finales | Web UI    | Demos y prototipos   |

**ğŸ“‹ DocumentaciÃ³n completa**: [`docs/GRADIO_INTERFACE.md`](docs/GRADIO_INTERFACE.md)

## ğŸ§ª Pruebas

```bash
# Ejecutar todas las pruebas
python -m pytest tests/ -v

# Pruebas especÃ­ficas
python -m pytest tests/test_data_validation.py -v

# Probar API (si estÃ¡ corriendo)
python test_api.py
```

## ğŸ“ Requisitos

- Python 3.8+
- scikit-learn 1.3+
- pandas 2.0+
- numpy 1.21+
- mlflow 2.0+ (opcional)
- dvc 3.0+ (opcional)

## ğŸ¤ ContribuciÃ³n

Este es un proyecto de portfolio que demuestra implementaciÃ³n profesional de MLOps siguiendo las mejores prÃ¡cticas de la industria.

## ğŸ“„ Licencia

Proyecto educativo - MIT License

---

## ï¿½ Estructura del Proyecto (Arquitectura HÃ­brida)

```
mlops-reproducible/
â”œâ”€â”€ src/                      # ğŸ”§ MÃ³dulos CLI (DVC Pipeline)
â”‚   â”œâ”€â”€ data/
â”‚   â”‚   â”œâ”€â”€ preprocess.py     # Limpieza y validaciÃ³n de datos
â”‚   â”‚   â””â”€â”€ make_features.py  # IngenierÃ­a de caracterÃ­sticas
â”‚   â””â”€â”€ models/
â”‚       â”œâ”€â”€ train.py          # Entrenamiento con MLflow
â”‚       â”œâ”€â”€ evaluate.py       # EvaluaciÃ³n y mÃ©tricas
â”‚       â””â”€â”€ predict.py        # Predicciones batch
â”œâ”€â”€ mlops/                    # ğŸ API Python (Uso Interactivo)
â”‚   â”œâ”€â”€ __init__.py          # InicializaciÃ³n del mÃ³dulo
â”‚   â”œâ”€â”€ config.py            # GestiÃ³n de configuraciÃ³n
â”‚   â”œâ”€â”€ dataset.py           # Procesamiento de datos
â”‚   â”œâ”€â”€ features.py          # IngenierÃ­a de caracterÃ­sticas
â”‚   â”œâ”€â”€ modeling.py          # Entrenamiento y evaluaciÃ³n
â”‚   â””â”€â”€ train.py            # Pipeline principal
â”œâ”€â”€ data/                    # ğŸ“Š Datos versionados con DVC
â”‚   â”œâ”€â”€ raw/                # Datos originales
â”‚   â”œâ”€â”€ interim/            # Datos procesados intermedio
â”‚   â””â”€â”€ processed/          # Datos finales procesados
â”œâ”€â”€ models/                  # ğŸ¤– Modelos entrenados
â”œâ”€â”€ notebooks/               # ğŸ““ Notebooks de exploraciÃ³n
â”œâ”€â”€ reports/                 # ğŸ“ˆ Reportes y mÃ©tricas
â”œâ”€â”€ docs/                    # ğŸ“š DocumentaciÃ³n
â”œâ”€â”€ tests/                   # ğŸ§ª Pruebas unitarias
â”œâ”€â”€ run_mlops.py            # ğŸš€ Interface unificada
â”œâ”€â”€ params.yaml              # âš™ï¸ ConfiguraciÃ³n principal
â”œâ”€â”€ dvc.yaml                 # ğŸ”„ Pipeline DVC
â””â”€â”€ requirements.txt         # ğŸ“¦ Dependencias
```

## ğŸ¯ Dos Enfoques, Una Funcionalidad

### **Enfoque 1: `src/` - MÃ³dulos CLI (Recomendado para ProducciÃ³n)**

- âœ… **DVC Integration** - Perfecto para pipelines automatizados
- âœ… **Modular** - Cada script es independiente
- âœ… **CI/CD Ready** - FÃ¡cil integraciÃ³n en workflows
- âœ… **MLflow Tracking** - Registro automÃ¡tico de experimentos

### **Enfoque 2: `mlops/` - Python API (Recomendado para Desarrollo)**

- âœ… **Interactive** - Perfecto para notebooks y experimentaciÃ³n
- âœ… **Clean API** - Interfaz Python elegante y fÃ¡cil de usar
- âœ… **Integrated** - Pipeline completo en una sola llamada
- âœ… **Flexible** - ConfiguraciÃ³n programÃ¡tica

---

## ğŸ§© Flujo MLOps implementado

````mermaid
flowchart LR
    A[Datos brutos] --> B[Limpieza y validaciÃ³n]
    B --> C[Feature Engineering]
    C --> D[Entrenamiento del modelo]
    D --> E[EvaluaciÃ³n y registro (MLflow)]
    E --> F[Despliegue (FastAPI / Docker)]
    F --> G[Monitoreo y retroalimentaciÃ³n]

âš™ï¸ TecnologÃ­as utilizadas

| CategorÃ­a                  | Herramienta           | PropÃ³sito                                  |
| -------------------------- | --------------------- | ------------------------------------------ |
| Control de versiones       | **Git / GitHub**      | Versionado de cÃ³digo y CI/CD               |
| Versionado de datos        | **DVC**               | Control y trazabilidad de datasets         |
| Tracking de experimentos   | **MLflow**            | Registro de parÃ¡metros, mÃ©tricas y modelos |
| AutomatizaciÃ³n de pipeline | **DVC Pipelines**     | EjecuciÃ³n reproducible de etapas           |
| Despliegue de API          | **FastAPI + Uvicorn** | Servir modelos en producciÃ³n               |
| Reproducibilidad           | **Conda / MLproject** | Control de entornos                        |
| Testing                    | **Pytest**            | VerificaciÃ³n funcional del pipeline        |
| CI/CD                      | **GitHub Actions**    | AutomatizaciÃ³n de ejecuciones y pruebas    |


âš™ï¸ InstalaciÃ³n y configuraciÃ³n

1ï¸âƒ£ Clonar el repositorio
git clone https://github.com/ALICIACANTA-MNA/mlops-reproducible.git
cd mlops-reproducible

2ï¸âƒ£ Crear entorno Conda
conda env create -f conda.yaml
conda activate mlops-reproducible

3ï¸âƒ£ Inicializar DVC
dvc init
dvc pull  # si existe almacenamiento remoto configurado

ğŸ§® EjecuciÃ³n del pipeline

Ejecutar todas las fases definidas en el archivo dvc.yaml:
```bash
    dvc repro

:: Visualizar mÃ©tricas:

dvc metrics show


:: Repetir con nuevos parÃ¡metros:

vi params.yaml
dvc repro && dvc metrics diff


ğŸ§  Registro y seguimiento de experimentos (MLflow)

:: Iniciar interfaz grÃ¡fica de MLflow:

mlflow ui

Abrir en el navegador: http://localhost:5000

Desde allÃ­ podrÃ¡s:
- Visualizar mÃ©tricas comparativas
- Registrar artefactos y modelos
- Seguir el historial de ejecuciones

ğŸŒ Despliegue local con FastAPI

:: Iniciar el servicio:
```bash
    uvicorn src.serving.api:app --reload --port 8080

:: Realizar una predicciÃ³n:
```bash
    curl -X POST "http://127.0.0.1:8080/predict" -H "Content-Type: application/json" \
     -d '{"Age":25,"Weight":80,"Height":1.70,"CH2O":2,"FAF":3,"FCVC":2,"TUE":1}'

ğŸ§ª Pruebas automÃ¡ticas

:: Ejecutar tests unitarios y de integraciÃ³n:
```bash
    pytest -q

ğŸ” IntegraciÃ³n continua (CI)
Cada push al repositorio activa el flujo de CI definido en .github/workflows/ci.yml, que ejecuta:
```bash
    dvc repro
    pytest
    dvc metrics show

Esto asegura reproducibilidad y validaciÃ³n automÃ¡tica de los cambios.

ğŸ§‘â€ğŸ’» Roles simulados en el flujo MLOps
Rol         	    Responsabilidad
Data Engineer	    Limpieza, integraciÃ³n y versionado de datos.
Data Scientist	    ExploraciÃ³n, modelado y mÃ©tricas.
ML Engineer	        Empaquetado, entrenamiento y evaluaciÃ³n automatizada.
DevOps Engineer	    AutomatizaciÃ³n, CI/CD y monitoreo de despliegues.

ğŸ“ˆ MÃ©tricas base (ejemplo)
MÃ©trica	        Valor
Accuracy	    0.972
F1-macro	    0.961
Recall	        0.958
Precision	    0.965

Los resultados pueden variar segÃºn los hiperparÃ¡metros definidos en params.yaml.

ğŸ§­ Lecciones aprendidas
- La reproducibilidad es la clave del Ã©xito en Machine Learning.
- Versionar datos y modelos permite auditar y mejorar continuamente.
- MLflow y DVC simplifican el control de experimentos.
- La colaboraciÃ³n entre roles tÃ©cnicos asegura trazabilidad y calidad.
- CI/CD garantiza estabilidad en cada versiÃ³n del pipeline.

ğŸ§© PrÃ³ximos pasos
- Incorporar monitoreo con EvidentlyAI.
- Automatizar el reentrenamiento por data drift.
- Contenerizar todo el flujo con Docker Compose.
- Desplegar en nube (AWS / Azure / GCP).

ğŸ“š Referencias
- Introducing MLOps â€“ Mark Treveil, Oâ€™Reilly Media (2020).
- Machine Learning Engineering in Action â€“ Ben Wilson (2022).
- DocumentaciÃ³n oficial: DVC
 | MLflow

ğŸ ConclusiÃ³n

â€œLa reproducibilidad es el puente entre la experimentaciÃ³n y la producciÃ³n.â€
Este proyecto demuestra cÃ³mo implementar un flujo MLOps real: automatizado, trazable y escalable.


---

ğŸ“˜ **Instrucciones finales:**
1. Copia todo el bloque de arriba.
2. Crea un nuevo archivo llamado `README.md` en tu repositorio local (`mlops-reproducible/`).
3. Pega el contenido y guarda.
4. Ejecuta:
   ```bash
   git add README.md
   git commit -m "Add professional README for MLOps reproducible project"
   git push origin main
````
